# CARTESIA PYTHON CODEBASE COLLECTION
# Generated on: 2025-02-27 23:06:37
# Total files: 71
# Root directory: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts

================================================================================

FILE_START: __init__.py (1/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/__init__.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .types import (
    CancelContextRequest,
    ContextId,
    Controls,
    Emotion,
    FlushId,
    GenerationRequest,
    Mp3OutputFormat,
    NaturalSpecifier,
    NumericalSpecifier,
    OutputFormat,
    OutputFormat_Mp3,
    OutputFormat_Raw,
    OutputFormat_Wav,
    PhonemeTimestamps,
    RawEncoding,
    RawOutputFormat,
    Speed,
    SupportedLanguage,
    TtsRequest,
    TtsRequestEmbeddingSpecifier,
    TtsRequestIdSpecifier,
    TtsRequestVoiceSpecifier,
    WavOutputFormat,
    WebSocketBaseResponse,
    WebSocketChunkResponse,
    WebSocketDoneResponse,
    WebSocketErrorResponse,
    WebSocketFlushDoneResponse,
    WebSocketPhonemeTimestampsResponse,
    WebSocketRawOutputFormat,
    WebSocketRequest,
    WebSocketResponse,
    WebSocketResponse_Chunk,
    WebSocketResponse_Done,
    WebSocketResponse_Error,
    WebSocketResponse_FlushDone,
    WebSocketResponse_PhonemeTimestamps,
    WebSocketResponse_Timestamps,
    WebSocketStreamOptions,
    WebSocketTimestampsResponse,
    WebSocketTtsOutput,
    WebSocketTtsRequest,
    WordTimestamps,
)
from .requests import (
    CancelContextRequestParams,
    ControlsParams,
    GenerationRequestParams,
    Mp3OutputFormatParams,
    OutputFormatParams,
    OutputFormat_Mp3Params,
    OutputFormat_RawParams,
    OutputFormat_WavParams,
    PhonemeTimestampsParams,
    RawOutputFormatParams,
    SpeedParams,
    TtsRequestEmbeddingSpecifierParams,
    TtsRequestIdSpecifierParams,
    TtsRequestParams,
    TtsRequestVoiceSpecifierParams,
    WavOutputFormatParams,
    WebSocketBaseResponseParams,
    WebSocketChunkResponseParams,
    WebSocketDoneResponseParams,
    WebSocketErrorResponseParams,
    WebSocketFlushDoneResponseParams,
    WebSocketPhonemeTimestampsResponseParams,
    WebSocketRawOutputFormatParams,
    WebSocketRequestParams,
    WebSocketResponseParams,
    WebSocketResponse_ChunkParams,
    WebSocketResponse_DoneParams,
    WebSocketResponse_ErrorParams,
    WebSocketResponse_FlushDoneParams,
    WebSocketResponse_PhonemeTimestampsParams,
    WebSocketResponse_TimestampsParams,
    WebSocketStreamOptionsParams,
    WebSocketTimestampsResponseParams,
    WebSocketTtsOutputParams,
    WebSocketTtsRequestParams,
    WordTimestampsParams,
)

__all__ = [
    "CancelContextRequest",
    "CancelContextRequestParams",
    "ContextId",
    "Controls",
    "ControlsParams",
    "Emotion",
    "FlushId",
    "GenerationRequest",
    "GenerationRequestParams",
    "Mp3OutputFormat",
    "Mp3OutputFormatParams",
    "NaturalSpecifier",
    "NumericalSpecifier",
    "OutputFormat",
    "OutputFormatParams",
    "OutputFormat_Mp3",
    "OutputFormat_Mp3Params",
    "OutputFormat_Raw",
    "OutputFormat_RawParams",
    "OutputFormat_Wav",
    "OutputFormat_WavParams",
    "PhonemeTimestamps",
    "PhonemeTimestampsParams",
    "RawEncoding",
    "RawOutputFormat",
    "RawOutputFormatParams",
    "Speed",
    "SpeedParams",
    "SupportedLanguage",
    "TtsRequest",
    "TtsRequestEmbeddingSpecifier",
    "TtsRequestEmbeddingSpecifierParams",
    "TtsRequestIdSpecifier",
    "TtsRequestIdSpecifierParams",
    "TtsRequestParams",
    "TtsRequestVoiceSpecifier",
    "TtsRequestVoiceSpecifierParams",
    "WavOutputFormat",
    "WavOutputFormatParams",
    "WebSocketBaseResponse",
    "WebSocketBaseResponseParams",
    "WebSocketChunkResponse",
    "WebSocketChunkResponseParams",
    "WebSocketDoneResponse",
    "WebSocketDoneResponseParams",
    "WebSocketErrorResponse",
    "WebSocketErrorResponseParams",
    "WebSocketFlushDoneResponse",
    "WebSocketFlushDoneResponseParams",
    "WebSocketPhonemeTimestampsResponse",
    "WebSocketPhonemeTimestampsResponseParams",
    "WebSocketRawOutputFormat",
    "WebSocketRawOutputFormatParams",
    "WebSocketRequest",
    "WebSocketRequestParams",
    "WebSocketResponse",
    "WebSocketResponseParams",
    "WebSocketResponse_Chunk",
    "WebSocketResponse_ChunkParams",
    "WebSocketResponse_Done",
    "WebSocketResponse_DoneParams",
    "WebSocketResponse_Error",
    "WebSocketResponse_ErrorParams",
    "WebSocketResponse_FlushDone",
    "WebSocketResponse_FlushDoneParams",
    "WebSocketResponse_PhonemeTimestamps",
    "WebSocketResponse_PhonemeTimestampsParams",
    "WebSocketResponse_Timestamps",
    "WebSocketResponse_TimestampsParams",
    "WebSocketStreamOptions",
    "WebSocketStreamOptionsParams",
    "WebSocketTimestampsResponse",
    "WebSocketTimestampsResponseParams",
    "WebSocketTtsOutput",
    "WebSocketTtsOutputParams",
    "WebSocketTtsRequest",
    "WebSocketTtsRequestParams",
    "WordTimestamps",
    "WordTimestampsParams",
]


--------------------------------------------------------------------------------
FILE_END: __init__.py

================================================================================

FILE_START: _async_websocket.py (2/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/_async_websocket.py
--------------------------------------------------------------------------------

import asyncio
import json
import typing
import uuid
from collections import defaultdict
from types import TracebackType
from typing import Any, AsyncGenerator, Callable, Dict, List, Optional, Union

import aiohttp

from cartesia.tts.requests import TtsRequestVoiceSpecifierParams
from cartesia.tts.requests.output_format import OutputFormatParams
from cartesia.tts.types import (
    WebSocketResponse,
    WebSocketResponse_Done,
    WebSocketResponse_Error,
    WebSocketResponse_FlushDone,
    WebSocketTtsOutput,
    WordTimestamps,
)

from ..core.pydantic_utilities import parse_obj_as
from ._websocket import TtsWebsocket
from .types.generation_request import GenerationRequest
from .utils.constants import (
    DEFAULT_MODEL_ID,
    DEFAULT_OUTPUT_FORMAT,
    DEFAULT_VOICE_EMBEDDING,
)
from .utils.tts import get_output_format


class _AsyncTTSContext:
    """Manage a single context over an AsyncWebSocket.

    This class separates sending requests and receiving responses into two separate methods.
    This can be used for sending multiple requests without awaiting the response.
    Then you can listen to the responses in the order they were sent. See README for usage.

    Each AsyncTTSContext will close automatically when a done message is received for that context.
    This happens when the no_more_inputs method is called (equivalent to sending a request with `continue_ = False`),
    or if no requests have been sent for 5 seconds on the same context. It also closes if there is an error.

    """

    def __init__(
        self, context_id: str, websocket: "AsyncTtsWebsocket", timeout: float = 30
    ):
        self._context_id = context_id
        self._websocket = websocket
        self.timeout = timeout
        self._error = None

    @property
    def context_id(self) -> str:
        return self._context_id

    async def send(
        self,
        *,
        model_id: str,
        transcript: str,
        output_format: OutputFormatParams,
        voice: TtsRequestVoiceSpecifierParams,
        context_id: Optional[str] = None,
        duration: Optional[int] = None,
        language: Optional[str] = None,
        stream: bool = True,
        add_timestamps: bool = False,
        continue_: bool = False,
        flush: bool = False,
    ) -> None:
        """Send audio generation requests to the WebSocket. The response can be received using the `receive` method.

        Args:
            request: The request to generate audio.

        Returns:
            None.
        """
        await self._websocket.connect()
        assert self._websocket.websocket is not None, "WebSocket is not connected"

        request_body = {
            "model_id": model_id,
            "transcript": transcript,
            "output_format": (
                output_format
                if isinstance(output_format, dict)
                else output_format.dict()
            ),
            "voice": (voice if isinstance(voice, dict) else voice.dict()),
            "context_id": self._context_id,
        }
        if context_id is not None:
            request_body["context_id"] = context_id
        if duration is not None:
            request_body["duration"] = duration
        if language is not None:
            request_body["language"] = language
        if stream:
            request_body["stream"] = stream
        if add_timestamps:
            request_body["add_timestamps"] = add_timestamps
        if continue_:
            request_body["continue"] = continue_
        if flush:
            request_body["flush"] = flush

        if (
            "context_id" in request_body
            and request_body["context_id"] is not None
            and request_body["context_id"] != self._context_id
        ):
            raise ValueError(
                "Context ID does not match the context ID of the current context."
            )
        request_body["context_id"] = self._context_id

        if (
            "continue" in request_body
            and request_body["continue"]
            and request_body["transcript"] == ""
            and ("flush" in request_body and not request_body["flush"])
        ):
            raise ValueError("Transcript cannot be empty when continue_ is True.")

        await self._websocket.websocket.send_json(request_body)

        # Start listening for responses on the WebSocket
        self._websocket._dispatch_listener()

    async def no_more_inputs(self) -> None:
        """Send a request to the WebSocket to indicate that no more requests will be sent."""
        await self.send(
            model_id=DEFAULT_MODEL_ID,
            transcript="",
            output_format=get_output_format(DEFAULT_OUTPUT_FORMAT),
            voice={
                "mode": "embedding",
                "embedding": DEFAULT_VOICE_EMBEDDING,
            },
            context_id=self._context_id,
            continue_=False,
        )

    async def flush(self) -> Callable[[], AsyncGenerator[Dict[str, Any], None]]:
        """Trigger a manual flush for the current context's generation. This method returns a generator that yields the audio prior to the flush."""
        await self.send(
            model_id=DEFAULT_MODEL_ID,
            transcript="",
            output_format=get_output_format(DEFAULT_OUTPUT_FORMAT),
            voice={
                "mode": "embedding",
                "embedding": DEFAULT_VOICE_EMBEDDING,
            },
            context_id=self._context_id,
            continue_=True,
            flush=True,
        )

        # Save the old flush ID
        flush_id = len(self._websocket._context_queues[self._context_id]) - 1

        # Create a new Async Queue to store the responses for the new flush ID
        self._websocket._context_queues[self._context_id].append(asyncio.Queue())

        # Return the generator for the old flush ID
        async def generator():
            try:
                while True:
                    response = await self._websocket._get_message(
                        self._context_id, timeout=self.timeout, flush_id=flush_id
                    )
                    response_obj = typing.cast(
                        WebSocketResponse,
                        parse_obj_as(
                            type_=WebSocketResponse, object_=response  # type: ignore
                        ),
                    )
                    if isinstance(response_obj, WebSocketResponse_Error):
                        raise RuntimeError(
                            f"Error generating audio:\n{response_obj.error}"
                        )
                    if isinstance(response_obj, WebSocketResponse_Done) or isinstance(
                        response_obj, WebSocketResponse_FlushDone
                    ):
                        break
                    yield self._websocket._convert_response(
                        response_obj, include_context_id=True
                    )
            except Exception as e:
                if isinstance(e, asyncio.TimeoutError):
                    raise RuntimeError("Timeout while waiting for audio chunk")
                raise RuntimeError(f"Failed to generate audio:\n{e}")

        return generator

    async def receive(self) -> AsyncGenerator[WebSocketTtsOutput, None]:
        """Receive the audio chunks from the WebSocket. This method is a generator that yields audio chunks.

        Returns:
            An async generator that yields audio chunks. Each chunk is a dictionary containing the audio as bytes.
        """
        try:
            while True:
                response = await self._websocket._get_message(
                    self._context_id, timeout=self.timeout
                )
                response_obj = typing.cast(
                    WebSocketResponse,
                    parse_obj_as(
                        type_=WebSocketResponse,  # type: ignore
                        object_=response,
                    ),
                )

                if isinstance(response_obj, WebSocketResponse_Error):
                    raise RuntimeError(f"Error generating audio:\n{response_obj.error}")
                if isinstance(response_obj, WebSocketResponse_Done):
                    break
                yield self._websocket._convert_response(
                    response_obj, include_context_id=True
                )
        except Exception as e:
            if isinstance(e, asyncio.TimeoutError):
                raise RuntimeError("Timeout while waiting for audio chunk")
            raise RuntimeError(f"Failed to generate audio:\n{e}")
        finally:
            self._close()

    def _close(self) -> None:
        """Closes the context. Automatically called when a done message is received for this context."""
        self._websocket._remove_context(self._context_id)

    def is_closed(self):
        """Check if the context is closed or not. Returns True if closed."""
        return self._context_id not in self._websocket._context_queues

    async def __aenter__(self):
        return self

    async def __aexit__(
        self,
        exc_type: Union[type, None],
        exc: Union[BaseException, None],
        exc_tb: Union[TracebackType, None],
    ):
        self._close()

    def __del__(self):
        self._close()


class AsyncTtsWebsocket(TtsWebsocket):
    """This class contains methods to generate audio using WebSocket asynchronously."""

    def __init__(
        self,
        ws_url: str,
        api_key: str,
        cartesia_version: str,
        get_session: Callable[[], Optional[aiohttp.ClientSession]],
        timeout: float = 30,
    ):
        """
        Args:
            ws_url: The WebSocket URL for the Cartesia API.
            api_key: The API key to use for authorization.
            cartesia_version: The version of the Cartesia API to use.
            timeout: The timeout for responses on the WebSocket in seconds.
            get_session: A function that returns an aiohttp.ClientSession object.
        """
        super().__init__(ws_url, api_key, cartesia_version)
        self.timeout = timeout
        self._get_session = get_session
        self.websocket = None
        self._context_queues: Dict[str, List[asyncio.Queue]] = {}
        self._processing_task: Optional[asyncio.Task] = None

    def __del__(self):
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = None

        if loop is None:
            asyncio.run(self.close())
        elif loop.is_running():
            loop.create_task(self.close())

    async def connect(self):
        if self.websocket is None or self._is_websocket_closed():
            route = "tts/websocket"
            session = await self._get_session()
            url = f"{self.ws_url}/{route}?api_key={self.api_key}&cartesia_version={self.cartesia_version}"
            try:
                self.websocket = await session.ws_connect(url)
            except Exception as e:
                raise RuntimeError(f"Failed to connect to WebSocket at {url}. {e}")

    def _is_websocket_closed(self):
        return self.websocket.closed

    async def close(self):
        """This method closes the websocket connection. *Highly* recommended to call this method when done."""
        if self.websocket is not None and not self._is_websocket_closed():
            await self.websocket.close()
        if self._processing_task:
            self._processing_task.cancel()
            try:
                self._processing_task = None
            except asyncio.CancelledError:
                pass
            except TypeError as e:
                # Ignore the error if the task is already canceled.
                # For some reason we are getting None responses
                # TODO: This needs to be fixed - we need to think about why we are getting None responses.
                if "Received message 256:None" not in str(e):
                    raise e

        for context_id in list(self._context_queues.keys()):
            self._remove_context(context_id)

        self._context_queues.clear()
        self._processing_task = None
        self.websocket = None

    async def send(
        self,
        *,
        model_id: str,
        transcript: str,
        output_format: OutputFormatParams,
        voice: TtsRequestVoiceSpecifierParams,
        context_id: Optional[str] = None,
        duration: Optional[int] = None,
        language: Optional[str] = None,
        stream: bool = True,
        add_timestamps: bool = False,
    ):
        """See :meth:`_WebSocket.send` for details."""
        if context_id is None:
            context_id = str(uuid.uuid4())

        ctx = self.context(context_id)

        await ctx.send(
            model_id=model_id,
            transcript=transcript,
            output_format=output_format,
            voice=voice,
            context_id=context_id,
            duration=duration,
            language=language,
            continue_=False,
            add_timestamps=add_timestamps,
        )

        generator = ctx.receive()

        if stream:
            return generator

        chunks: typing.List[str] = []
        words: typing.List[str] = []
        start: typing.List[float] = []
        end: typing.List[float] = []
        async for chunk in generator:
            if chunk.audio is not None:
                chunks.append(chunk.audio)
            if add_timestamps and chunk.word_timestamps is not None:
                if chunk.word_timestamps is not None:
                    words.extend(chunk.word_timestamps.words)
                    start.extend(chunk.word_timestamps.start)
                    end.extend(chunk.word_timestamps.end)

        return WebSocketTtsOutput(
            audio=b"".join(chunks),  # type: ignore
            context_id=context_id,
            word_timestamps=(
                WordTimestamps(
                    words=words,
                    start=start,
                    end=end,
                )
                if add_timestamps
                else None
            ),
        )

    async def _process_responses(self):
        try:
            while True:
                response = await self.websocket.receive_json()
                if response["context_id"]:
                    context_id = response["context_id"]
                flush_id = response.get("flush_id", -1)
                if context_id in self._context_queues:
                    await self._context_queues[context_id][flush_id].put(response)
        except Exception as e:
            self._error = e
            raise e

    async def _get_message(
        self, context_id: str, timeout: float, flush_id: int = -1
    ) -> Dict[str, Any]:
        if context_id not in self._context_queues:
            raise ValueError(f"Context ID {context_id} not found.")
        if len(self._context_queues[context_id]) <= flush_id:
            raise ValueError(
                f"Flush ID {flush_id} not found for context ID {context_id}."
            )
        return await asyncio.wait_for(
            self._context_queues[context_id][flush_id].get(), timeout=timeout
        )

    def _remove_context(self, context_id: str):
        if context_id in self._context_queues:
            del self._context_queues[context_id]

    def _dispatch_listener(self):
        if self._processing_task is None or self._processing_task.done():
            self._processing_task = asyncio.create_task(self._process_responses())

    def context(self, context_id: Optional[str] = None):
        if context_id in self._context_queues:
            raise ValueError(
                f"AsyncContext for context ID {context_id} already exists."
            )
        if context_id is None:
            context_id = str(uuid.uuid4())
        if context_id not in self._context_queues:
            self._context_queues[context_id] = [asyncio.Queue()]
        return _AsyncTTSContext(context_id, self, self.timeout)


--------------------------------------------------------------------------------
FILE_END: _async_websocket.py

================================================================================

FILE_START: _websocket.py (3/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/_websocket.py
--------------------------------------------------------------------------------

import base64
import json
import typing
import uuid
from collections import defaultdict
from typing import Any, Dict, Generator, Optional, Set, Union

try:
    from websockets.sync.client import connect

    IS_WEBSOCKET_SYNC_AVAILABLE = True
except ImportError:
    IS_WEBSOCKET_SYNC_AVAILABLE = False

from iterators import TimeoutIterator  # type: ignore

from cartesia.tts.requests import TtsRequestVoiceSpecifierParams
from cartesia.tts.requests.output_format import OutputFormatParams
from cartesia.tts.types import (
    WebSocketResponse,
    WebSocketResponse_Chunk,
    WebSocketResponse_Done,
    WebSocketResponse_Error,
    WebSocketResponse_FlushDone,
    WebSocketResponse_PhonemeTimestamps,
    WebSocketResponse_Timestamps,
    WebSocketTtsOutput,
    WordTimestamps,
)

from ..core.pydantic_utilities import parse_obj_as
from .types.generation_request import GenerationRequest


class _TTSContext:
    """Manage a single context over a WebSocket.

    This class can be used to stream inputs, as they become available, to a specific `context_id`. See README for usage.

    See :class:`_AsyncTTSContext` for asynchronous use cases.

    Each TTSContext will close automatically when a done message is received for that context. It also closes if there is an error.
    """

    def __init__(self, context_id: str, websocket: "TtsWebsocket"):
        self._context_id = context_id
        self._websocket = websocket
        self._error = None

    def __del__(self):
        self._close()

    @property
    def context_id(self) -> str:
        return self._context_id

    def send(
        self,
        *,
        model_id: str,
        transcript: str,
        output_format: OutputFormatParams,
        voice: TtsRequestVoiceSpecifierParams,
        context_id: Optional[str] = None,
        duration: Optional[int] = None,
        language: Optional[str] = None,
        stream: bool = True,
        add_timestamps: bool = False,
    ) -> Generator[bytes, None, None]:
        """Send audio generation requests to the WebSocket and yield responses.

        Args:
            request: The request to generate audio.

        Yields:
            Dictionary containing the following key(s):
            - audio: The audio as bytes.
            - context_id: The context ID for the request.

        Raises:
            ValueError: If provided context_id doesn't match the current context.
            RuntimeError: If there's an error generating audio.
        """
        self._websocket.connect()
        assert self._websocket.websocket is not None, "WebSocket is not connected"

        request_body = {
            "model_id": model_id,
            "transcript": transcript,
            "output_format": output_format,
            "voice": voice,
            "context_id": self._context_id,
        }
        if context_id is not None:
            request_body["context_id"] = context_id
        if duration is not None:
            request_body["duration"] = duration
        if language is not None:
            request_body["language"] = language
        if stream:
            request_body["stream"] = stream
        if add_timestamps:
            request_body["add_timestamps"] = add_timestamps

        if (
            "context_id" in request_body
            and request_body["context_id"] is not None
            and request_body["context_id"] != self._context_id
        ):
            raise ValueError(
                "Context ID does not match the context ID of the current context."
            )

        try:
            text_iterator = TimeoutIterator(request_body["transcript"], timeout=0.001)
            next_chunk = next(text_iterator, None)

            while True:
                # Send the next text chunk to the WebSocket if available
                if (
                    next_chunk is not None
                    and next_chunk != text_iterator.get_sentinel()
                ):
                    request_body["transcript"] = next_chunk
                    request_body["continue"] = True
                    self._websocket.websocket.send(json.dumps(request_body))
                    next_chunk = next(text_iterator, None)

                try:
                    # Receive responses from the WebSocket with a small timeout
                    response_obj = typing.cast(
                        WebSocketResponse,
                        parse_obj_as(
                            type_=WebSocketResponse,  # type: ignore
                            object_=json.loads(
                                self._websocket.websocket.recv(timeout=0.001)
                            ),
                        ),
                    )
                    if response_obj.context_id != self._context_id:
                        pass
                    if isinstance(response_obj, WebSocketResponse_Error):
                        raise RuntimeError(
                            f"Error generating audio:\n{response_obj.error}"
                        )
                    if isinstance(response_obj, WebSocketResponse_Done):
                        break
                    if (
                        isinstance(response_obj, WebSocketResponse_Chunk)
                        or isinstance(response_obj, WebSocketResponse_Timestamps)
                        or isinstance(response_obj, WebSocketResponse_PhonemeTimestamps)
                    ):
                        yield self._websocket._convert_response(
                            response_obj, include_context_id=True
                        )
                except TimeoutError:
                    pass

                # Continuously receive from WebSocket until the next text chunk is available
                while next_chunk == text_iterator.get_sentinel():
                    try:
                        response_obj = typing.cast(
                            WebSocketResponse,
                            parse_obj_as(
                                type_=WebSocketResponse,  # type: ignore
                                object_=json.loads(
                                    self._websocket.websocket.recv(timeout=0.001)
                                ),
                            ),
                        )
                        if response_obj.context_id != self._context_id:
                            continue
                        if isinstance(response_obj, WebSocketResponse_Error):
                            raise RuntimeError(
                                f"Error generating audio:\n{response_obj.error}"
                            )
                        if isinstance(response_obj, WebSocketResponse_Done):
                            break
                        if (
                            isinstance(response_obj, WebSocketResponse_Chunk)
                            or isinstance(response_obj, WebSocketResponse_Timestamps)
                            or isinstance(
                                response_obj, WebSocketResponse_PhonemeTimestamps
                            )
                        ):
                            yield self._websocket._convert_response(
                                response_obj, include_context_id=True
                            )
                    except TimeoutError:
                        pass
                    next_chunk = next(text_iterator, None)

                # Send final message if all input text chunks are exhausted
                if next_chunk is None:
                    request_body["transcript"] = ""
                    request_body["continue"] = False
                    self._websocket.websocket.send(json.dumps(request_body))
                    break

            # Receive remaining messages from the WebSocket until "done" is received
            while True:
                response_obj = typing.cast(
                    WebSocketResponse,
                    parse_obj_as(
                        type_=WebSocketResponse,  # type: ignore
                        object_=json.loads(self._websocket.websocket.recv()),
                    ),
                )
                if response_obj.context_id != self._context_id:
                    continue
                if isinstance(response_obj, WebSocketResponse_Error):
                    raise RuntimeError(f"Error generating audio:\n{response_obj.error}")
                if isinstance(response_obj, WebSocketResponse_Done):
                    break
                yield self._websocket._convert_response(
                    response_obj, include_context_id=True
                )

        except Exception as e:
            self._websocket.close()
            raise RuntimeError(f"Failed to generate audio. {e}")

    def _close(self):
        """Closes the context. Automatically called when a done message is received for this context."""
        self._websocket._remove_context(self._context_id)

    def is_closed(self):
        """Check if the context is closed or not. Returns True if closed."""
        return self._context_id not in self._websocket._contexts


class TtsWebsocket:
    """This class contains methods to generate audio using WebSocket. Ideal for low-latency audio generation.

    Usage:
        >>> ws = client.tts.websocket()
        >>> generation_request = GenerationRequest(
        ...     model_id="sonic-english",
        ...     transcript="Hello world!",
        ...     voice_embedding=embedding
        ...     output_format={"container": "raw", "encoding": "pcm_f32le", "sample_rate": 44100}
        ...     context_id=context_id,
        ...     stream=True
        ... )
        >>> for audio_chunk in ws.send(generation_request):
        ...     audio = audio_chunk["audio"]
    """

    def __init__(
        self,
        ws_url: str,
        api_key: str,
        cartesia_version: str,
    ):
        self.ws_url = ws_url
        self.api_key = api_key
        self.cartesia_version = cartesia_version
        self.websocket = None
        self._contexts: Set[str] = set()

    def __del__(self):
        try:
            self.close()
        except Exception as e:
            raise RuntimeError("Failed to close WebSocket: ", e)

    def connect(self):
        """This method connects to the WebSocket if it is not already connected.

        Raises:
            RuntimeError: If the connection to the WebSocket fails.
        """
        if not IS_WEBSOCKET_SYNC_AVAILABLE:
            raise ImportError(
                "The synchronous WebSocket client is not available. Please ensure that you have 'websockets>=12.0' or compatible version installed."
            )
        if self.websocket is None or self._is_websocket_closed():
            route = "tts/websocket"
            try:
                self.websocket = connect(
                    f"{self.ws_url}/{route}?api_key={self.api_key}&cartesia_version={self.cartesia_version}"
                )
            except Exception as e:
                raise RuntimeError(f"Failed to connect to WebSocket. {e}")

    def _is_websocket_closed(self):
        return self.websocket.socket.fileno() == -1

    def close(self):
        """This method closes the WebSocket connection. *Highly* recommended to call this method when done using the WebSocket."""
        if self.websocket and not self._is_websocket_closed():
            self.websocket.close()

        if self._contexts:
            self._contexts.clear()

    def _convert_response(
        self,
        response: typing.Union[
            WebSocketResponse_Chunk,
            WebSocketResponse_Timestamps,
            WebSocketResponse_PhonemeTimestamps,
            WebSocketResponse_FlushDone,
        ],
        include_context_id: bool,
        include_flush_id: bool = False,
    ) -> WebSocketTtsOutput:
        out = {}
        if isinstance(response, WebSocketResponse_Chunk):
            out["audio"] = base64.b64decode(response.data)
        elif isinstance(response, WebSocketResponse_Timestamps):
            out["word_timestamps"] = response.word_timestamps  # type: ignore
        elif include_flush_id and isinstance(response, WebSocketResponse_FlushDone):
            out["flush_done"] = response.flush_done  # type: ignore
            out["flush_id"] = response.flush_id  # type: ignore

        if include_context_id and response.context_id:
            out["context_id"] = response.context_id  # type: ignore

        return WebSocketTtsOutput(**out)  # type: ignore

    def send(
        self,
        *,
        model_id: str,
        transcript: str,
        output_format: OutputFormatParams,
        voice: TtsRequestVoiceSpecifierParams,
        context_id: Optional[str] = None,
        duration: Optional[int] = None,
        language: Optional[str] = None,
        stream: bool = True,
        add_timestamps: bool = False,
    ):
        """Send a request to the WebSocket to generate audio.

        Args:
            request: The request to generate audio.
            stream: Whether to stream the audio or not.

        Returns:
            If `stream` is True, the method returns a generator that yields chunks. Each chunk is a dictionary.
            If `stream` is False, the method returns a dictionary.
            Both the generator and the dictionary contain the following key(s):
            - audio: The audio as bytes.
            - context_id: The context ID for the request.
        """
        self.connect()

        if context_id is None:
            context_id = str(uuid.uuid4())

        request_body = {
            "model_id": model_id,
            "transcript": transcript,
            "output_format": output_format,
            "voice": voice,
            "context_id": context_id,
            "duration": duration,
            "language": language,
            "stream": stream,
            "add_timestamps": add_timestamps,
        }
        generator = self._websocket_generator(request_body)

        if stream:
            return generator

        chunks: typing.List[str] = []
        words: typing.List[str] = []
        start: typing.List[float] = []
        end: typing.List[float] = []
        for chunk in generator:
            if chunk.audio is not None:
                chunks.append(chunk.audio)
            if add_timestamps and chunk.word_timestamps is not None:
                if chunk.word_timestamps is not None:
                    words.extend(chunk.word_timestamps.words)
                    start.extend(chunk.word_timestamps.start)
                    end.extend(chunk.word_timestamps.end)

        return WebSocketTtsOutput(
            audio=b"".join(chunks),  # type: ignore
            context_id=context_id,
            word_timestamps=(
                WordTimestamps(
                    words=words,
                    start=start,
                    end=end,
                )
                if add_timestamps
                else None
            ),
        )

    def _websocket_generator(self, request_body: Dict[str, Any]):
        assert self.websocket is not None, "WebSocket is not connected"
        self.websocket.send(json.dumps(request_body))

        try:
            while True:
                response_obj = typing.cast(
                    WebSocketResponse,
                    parse_obj_as(
                        type_=WebSocketResponse,  # type: ignore
                        object_=json.loads(self.websocket.recv()),
                    ),
                )
                if isinstance(response_obj, WebSocketResponse_Error):
                    raise RuntimeError(f"Error generating audio:\n{response_obj.error}")
                if isinstance(response_obj, WebSocketResponse_Done):
                    break
                yield self._convert_response(response_obj, include_context_id=True)
        except Exception as e:
            # Close the websocket connection if an error occurs.
            self.close()
            raise RuntimeError(f"Failed to generate audio. {e}") from e

    def _remove_context(self, context_id: str):
        if context_id in self._contexts:
            self._contexts.remove(context_id)

    def context(self, context_id: Optional[str] = None):
        if context_id in self._contexts:
            raise ValueError(f"Context for context ID {context_id} already exists.")
        if context_id is None:
            context_id = str(uuid.uuid4())
        if context_id not in self._contexts:
            self._contexts.add(context_id)
        return _TTSContext(context_id, self)


--------------------------------------------------------------------------------
FILE_END: _websocket.py

================================================================================

FILE_START: client.py (4/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/client.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing
from ..core.client_wrapper import SyncClientWrapper
from .requests.tts_request_voice_specifier import TtsRequestVoiceSpecifierParams
from .requests.output_format import OutputFormatParams
from .types.supported_language import SupportedLanguage
from ..core.request_options import RequestOptions
from ..core.serialization import convert_and_respect_annotation_metadata
from json.decoder import JSONDecodeError
from ..core.api_error import ApiError
from .types.web_socket_response import WebSocketResponse
import httpx_sse
from ..core.pydantic_utilities import parse_obj_as
import json
from ..core.client_wrapper import AsyncClientWrapper

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class TtsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def bytes(
        self,
        *,
        model_id: str,
        transcript: str,
        voice: TtsRequestVoiceSpecifierParams,
        output_format: OutputFormatParams,
        language: typing.Optional[SupportedLanguage] = OMIT,
        duration: typing.Optional[float] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Iterator[bytes]:
        """
        Parameters
        ----------
        model_id : str
            The ID of the model to use for the generation. See [Models](/build-with-sonic/models) for available models.

        transcript : str

        voice : TtsRequestVoiceSpecifierParams

        output_format : OutputFormatParams

        language : typing.Optional[SupportedLanguage]

        duration : typing.Optional[float]
            The maximum duration of the audio in seconds. You do not usually need to specify this.
            If the duration is not appropriate for the length of the transcript, the output audio may be truncated.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.

        Yields
        ------
        typing.Iterator[bytes]

        Examples
        --------
        from cartesia import Cartesia

        client = Cartesia(
            api_key="YOUR_API_KEY",
        )
        client.tts.bytes(
            model_id="sonic",
            transcript="Hello, world!",
            voice={"mode": "id", "id": "694f9389-aac1-45b6-b726-9d9369183238"},
            language="en",
            output_format={
                "sample_rate": 44100,
                "bit_rate": 128000,
                "container": "mp3",
            },
        )
        """
        with self._client_wrapper.httpx_client.stream(
            "tts/bytes",
            method="POST",
            json={
                "model_id": model_id,
                "transcript": transcript,
                "voice": convert_and_respect_annotation_metadata(
                    object_=voice, annotation=TtsRequestVoiceSpecifierParams, direction="write"
                ),
                "language": language,
                "output_format": convert_and_respect_annotation_metadata(
                    object_=output_format, annotation=OutputFormatParams, direction="write"
                ),
                "duration": duration,
            },
            request_options=request_options,
            omit=OMIT,
        ) as _response:
            try:
                if 200 <= _response.status_code < 300:
                    _chunk_size = request_options.get("chunk_size", None) if request_options is not None else None
                    for _chunk in _response.iter_bytes(chunk_size=_chunk_size):
                        yield _chunk
                    return
                _response.read()
                _response_json = _response.json()
            except JSONDecodeError:
                raise ApiError(status_code=_response.status_code, body=_response.text)
            raise ApiError(status_code=_response.status_code, body=_response_json)

    def sse(
        self,
        *,
        model_id: str,
        transcript: str,
        voice: TtsRequestVoiceSpecifierParams,
        output_format: OutputFormatParams,
        language: typing.Optional[SupportedLanguage] = OMIT,
        duration: typing.Optional[float] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.Iterator[WebSocketResponse]:
        """
        Parameters
        ----------
        model_id : str
            The ID of the model to use for the generation. See [Models](/build-with-sonic/models) for available models.

        transcript : str

        voice : TtsRequestVoiceSpecifierParams

        output_format : OutputFormatParams

        language : typing.Optional[SupportedLanguage]

        duration : typing.Optional[float]
            The maximum duration of the audio in seconds. You do not usually need to specify this.
            If the duration is not appropriate for the length of the transcript, the output audio may be truncated.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Yields
        ------
        typing.Iterator[WebSocketResponse]

        Examples
        --------
        from cartesia import Cartesia

        client = Cartesia(
            api_key="YOUR_API_KEY",
        )
        response = client.tts.sse(
            model_id="sonic",
            transcript="Hello, world!",
            voice={"mode": "id", "id": "694f9389-aac1-45b6-b726-9d9369183238"},
            language="en",
            output_format={
                "sample_rate": 44100,
                "encoding": "pcm_f32le",
                "container": "raw",
            },
        )
        for chunk in response:
            yield chunk
        """
        with self._client_wrapper.httpx_client.stream(
            "tts/sse",
            method="POST",
            json={
                "model_id": model_id,
                "transcript": transcript,
                "voice": convert_and_respect_annotation_metadata(
                    object_=voice, annotation=TtsRequestVoiceSpecifierParams, direction="write"
                ),
                "language": language,
                "output_format": convert_and_respect_annotation_metadata(
                    object_=output_format, annotation=OutputFormatParams, direction="write"
                ),
                "duration": duration,
            },
            request_options=request_options,
            omit=OMIT,
        ) as _response:
            try:
                if 200 <= _response.status_code < 300:
                    _event_source = httpx_sse.EventSource(_response)
                    for _sse in _event_source.iter_sse():
                        try:
                            yield typing.cast(
                                WebSocketResponse,
                                parse_obj_as(
                                    type_=WebSocketResponse,  # type: ignore
                                    object_=json.loads(_sse.data),
                                ),
                            )
                        except:
                            pass
                    return
                _response.read()
                _response_json = _response.json()
            except JSONDecodeError:
                raise ApiError(status_code=_response.status_code, body=_response.text)
            raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncTtsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def bytes(
        self,
        *,
        model_id: str,
        transcript: str,
        voice: TtsRequestVoiceSpecifierParams,
        output_format: OutputFormatParams,
        language: typing.Optional[SupportedLanguage] = OMIT,
        duration: typing.Optional[float] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.AsyncIterator[bytes]:
        """
        Parameters
        ----------
        model_id : str
            The ID of the model to use for the generation. See [Models](/build-with-sonic/models) for available models.

        transcript : str

        voice : TtsRequestVoiceSpecifierParams

        output_format : OutputFormatParams

        language : typing.Optional[SupportedLanguage]

        duration : typing.Optional[float]
            The maximum duration of the audio in seconds. You do not usually need to specify this.
            If the duration is not appropriate for the length of the transcript, the output audio may be truncated.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration. You can pass in configuration such as `chunk_size`, and more to customize the request and response.

        Yields
        ------
        typing.AsyncIterator[bytes]

        Examples
        --------
        import asyncio

        from cartesia import AsyncCartesia

        client = AsyncCartesia(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.tts.bytes(
                model_id="sonic",
                transcript="Hello, world!",
                voice={"mode": "id", "id": "694f9389-aac1-45b6-b726-9d9369183238"},
                language="en",
                output_format={
                    "sample_rate": 44100,
                    "bit_rate": 128000,
                    "container": "mp3",
                },
            )


        asyncio.run(main())
        """
        async with self._client_wrapper.httpx_client.stream(
            "tts/bytes",
            method="POST",
            json={
                "model_id": model_id,
                "transcript": transcript,
                "voice": convert_and_respect_annotation_metadata(
                    object_=voice, annotation=TtsRequestVoiceSpecifierParams, direction="write"
                ),
                "language": language,
                "output_format": convert_and_respect_annotation_metadata(
                    object_=output_format, annotation=OutputFormatParams, direction="write"
                ),
                "duration": duration,
            },
            request_options=request_options,
            omit=OMIT,
        ) as _response:
            try:
                if 200 <= _response.status_code < 300:
                    _chunk_size = request_options.get("chunk_size", None) if request_options is not None else None
                    async for _chunk in _response.aiter_bytes(chunk_size=_chunk_size):
                        yield _chunk
                    return
                await _response.aread()
                _response_json = _response.json()
            except JSONDecodeError:
                raise ApiError(status_code=_response.status_code, body=_response.text)
            raise ApiError(status_code=_response.status_code, body=_response_json)

    async def sse(
        self,
        *,
        model_id: str,
        transcript: str,
        voice: TtsRequestVoiceSpecifierParams,
        output_format: OutputFormatParams,
        language: typing.Optional[SupportedLanguage] = OMIT,
        duration: typing.Optional[float] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.AsyncIterator[WebSocketResponse]:
        """
        Parameters
        ----------
        model_id : str
            The ID of the model to use for the generation. See [Models](/build-with-sonic/models) for available models.

        transcript : str

        voice : TtsRequestVoiceSpecifierParams

        output_format : OutputFormatParams

        language : typing.Optional[SupportedLanguage]

        duration : typing.Optional[float]
            The maximum duration of the audio in seconds. You do not usually need to specify this.
            If the duration is not appropriate for the length of the transcript, the output audio may be truncated.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Yields
        ------
        typing.AsyncIterator[WebSocketResponse]

        Examples
        --------
        import asyncio

        from cartesia import AsyncCartesia

        client = AsyncCartesia(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            response = await client.tts.sse(
                model_id="sonic",
                transcript="Hello, world!",
                voice={"mode": "id", "id": "694f9389-aac1-45b6-b726-9d9369183238"},
                language="en",
                output_format={
                    "sample_rate": 44100,
                    "encoding": "pcm_f32le",
                    "container": "raw",
                },
            )
            async for chunk in response:
                yield chunk


        asyncio.run(main())
        """
        async with self._client_wrapper.httpx_client.stream(
            "tts/sse",
            method="POST",
            json={
                "model_id": model_id,
                "transcript": transcript,
                "voice": convert_and_respect_annotation_metadata(
                    object_=voice, annotation=TtsRequestVoiceSpecifierParams, direction="write"
                ),
                "language": language,
                "output_format": convert_and_respect_annotation_metadata(
                    object_=output_format, annotation=OutputFormatParams, direction="write"
                ),
                "duration": duration,
            },
            request_options=request_options,
            omit=OMIT,
        ) as _response:
            try:
                if 200 <= _response.status_code < 300:
                    _event_source = httpx_sse.EventSource(_response)
                    async for _sse in _event_source.aiter_sse():
                        try:
                            yield typing.cast(
                                WebSocketResponse,
                                parse_obj_as(
                                    type_=WebSocketResponse,  # type: ignore
                                    object_=json.loads(_sse.data),
                                ),
                            )
                        except:
                            pass
                    return
                await _response.aread()
                _response_json = _response.json()
            except JSONDecodeError:
                raise ApiError(status_code=_response.status_code, body=_response.text)
            raise ApiError(status_code=_response.status_code, body=_response_json)


--------------------------------------------------------------------------------
FILE_END: client.py

================================================================================

FILE_START: requests/__init__.py (5/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/__init__.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .cancel_context_request import CancelContextRequestParams
from .controls import ControlsParams
from .generation_request import GenerationRequestParams
from .mp_3_output_format import Mp3OutputFormatParams
from .output_format import OutputFormatParams, OutputFormat_Mp3Params, OutputFormat_RawParams, OutputFormat_WavParams
from .phoneme_timestamps import PhonemeTimestampsParams
from .raw_output_format import RawOutputFormatParams
from .speed import SpeedParams
from .tts_request import TtsRequestParams
from .tts_request_embedding_specifier import TtsRequestEmbeddingSpecifierParams
from .tts_request_id_specifier import TtsRequestIdSpecifierParams
from .tts_request_voice_specifier import TtsRequestVoiceSpecifierParams
from .wav_output_format import WavOutputFormatParams
from .web_socket_base_response import WebSocketBaseResponseParams
from .web_socket_chunk_response import WebSocketChunkResponseParams
from .web_socket_done_response import WebSocketDoneResponseParams
from .web_socket_error_response import WebSocketErrorResponseParams
from .web_socket_flush_done_response import WebSocketFlushDoneResponseParams
from .web_socket_phoneme_timestamps_response import WebSocketPhonemeTimestampsResponseParams
from .web_socket_raw_output_format import WebSocketRawOutputFormatParams
from .web_socket_request import WebSocketRequestParams
from .web_socket_response import (
    WebSocketResponseParams,
    WebSocketResponse_ChunkParams,
    WebSocketResponse_DoneParams,
    WebSocketResponse_ErrorParams,
    WebSocketResponse_FlushDoneParams,
    WebSocketResponse_PhonemeTimestampsParams,
    WebSocketResponse_TimestampsParams,
)
from .web_socket_stream_options import WebSocketStreamOptionsParams
from .web_socket_timestamps_response import WebSocketTimestampsResponseParams
from .web_socket_tts_output import WebSocketTtsOutputParams
from .web_socket_tts_request import WebSocketTtsRequestParams
from .word_timestamps import WordTimestampsParams

__all__ = [
    "CancelContextRequestParams",
    "ControlsParams",
    "GenerationRequestParams",
    "Mp3OutputFormatParams",
    "OutputFormatParams",
    "OutputFormat_Mp3Params",
    "OutputFormat_RawParams",
    "OutputFormat_WavParams",
    "PhonemeTimestampsParams",
    "RawOutputFormatParams",
    "SpeedParams",
    "TtsRequestEmbeddingSpecifierParams",
    "TtsRequestIdSpecifierParams",
    "TtsRequestParams",
    "TtsRequestVoiceSpecifierParams",
    "WavOutputFormatParams",
    "WebSocketBaseResponseParams",
    "WebSocketChunkResponseParams",
    "WebSocketDoneResponseParams",
    "WebSocketErrorResponseParams",
    "WebSocketFlushDoneResponseParams",
    "WebSocketPhonemeTimestampsResponseParams",
    "WebSocketRawOutputFormatParams",
    "WebSocketRequestParams",
    "WebSocketResponseParams",
    "WebSocketResponse_ChunkParams",
    "WebSocketResponse_DoneParams",
    "WebSocketResponse_ErrorParams",
    "WebSocketResponse_FlushDoneParams",
    "WebSocketResponse_PhonemeTimestampsParams",
    "WebSocketResponse_TimestampsParams",
    "WebSocketStreamOptionsParams",
    "WebSocketTimestampsResponseParams",
    "WebSocketTtsOutputParams",
    "WebSocketTtsRequestParams",
    "WordTimestampsParams",
]


--------------------------------------------------------------------------------
FILE_END: requests/__init__.py

================================================================================

FILE_START: requests/cancel_context_request.py (6/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/cancel_context_request.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
from ..types.context_id import ContextId
import typing


class CancelContextRequestParams(typing_extensions.TypedDict):
    context_id: ContextId
    """
    The ID of the context to cancel.
    """

    cancel: typing.Literal[True]
    """
    Whether to cancel the context, so that no more messages are generated for that context.
    """


--------------------------------------------------------------------------------
FILE_END: requests/cancel_context_request.py

================================================================================

FILE_START: requests/controls.py (7/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/controls.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
from .speed import SpeedParams
import typing
from ..types.emotion import Emotion


class ControlsParams(typing_extensions.TypedDict):
    speed: SpeedParams
    emotion: typing.Sequence[Emotion]


--------------------------------------------------------------------------------
FILE_END: requests/controls.py

================================================================================

FILE_START: requests/generation_request.py (8/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/generation_request.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing
from .tts_request_voice_specifier import TtsRequestVoiceSpecifierParams
import typing_extensions
from ..types.supported_language import SupportedLanguage
from .web_socket_raw_output_format import WebSocketRawOutputFormatParams
from ..types.context_id import ContextId
from ...core.serialization import FieldMetadata


class GenerationRequestParams(typing_extensions.TypedDict):
    model_id: str
    """
    The ID of the model to use for the generation. See [Models](/build-with-sonic/models) for available models.
    """

    transcript: typing.Optional[typing.Any]
    """
    The transcript to generate speech for. This can be a string or an iterator over strings.
    """

    voice: TtsRequestVoiceSpecifierParams
    language: typing_extensions.NotRequired[SupportedLanguage]
    output_format: WebSocketRawOutputFormatParams
    duration: typing_extensions.NotRequired[float]
    """
    The maximum duration of the audio in seconds. You do not usually need to specify this.
    If the duration is not appropriate for the length of the transcript, the output audio may be truncated.
    """

    context_id: typing_extensions.NotRequired[ContextId]
    continue_: typing_extensions.NotRequired[typing_extensions.Annotated[bool, FieldMetadata(alias="continue")]]
    """
    Whether this input may be followed by more inputs.
    If not specified, this defaults to `false`.
    """

    flush: typing_extensions.NotRequired[bool]
    """
    Whether to flush the context.
    """

    add_timestamps: typing_extensions.NotRequired[bool]
    """
    Whether to return word-level timestamps.
    """

    add_phoneme_timestamps: typing_extensions.NotRequired[bool]
    """
    Whether to return phoneme-level timestamps.
    """


--------------------------------------------------------------------------------
FILE_END: requests/generation_request.py

================================================================================

FILE_START: requests/mp_3_output_format.py (9/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/mp_3_output_format.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions


class Mp3OutputFormatParams(typing_extensions.TypedDict):
    sample_rate: int
    bit_rate: int
    """
    The bit rate of the audio in bits per second. Supported bit rates are 32000, 64000, 96000, 128000, 192000.
    """


--------------------------------------------------------------------------------
FILE_END: requests/mp_3_output_format.py

================================================================================

FILE_START: requests/output_format.py (10/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/output_format.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from __future__ import annotations
import typing_extensions
import typing
from ..types.raw_encoding import RawEncoding
import typing_extensions


class OutputFormat_RawParams(typing_extensions.TypedDict):
    container: typing.Literal["raw"]
    encoding: RawEncoding
    sample_rate: int
    bit_rate: typing_extensions.NotRequired[int]


class OutputFormat_WavParams(typing_extensions.TypedDict):
    container: typing.Literal["wav"]
    encoding: RawEncoding
    sample_rate: int
    bit_rate: typing_extensions.NotRequired[int]


class OutputFormat_Mp3Params(typing_extensions.TypedDict):
    container: typing.Literal["mp3"]
    sample_rate: int
    bit_rate: int


OutputFormatParams = typing.Union[OutputFormat_RawParams, OutputFormat_WavParams, OutputFormat_Mp3Params]


--------------------------------------------------------------------------------
FILE_END: requests/output_format.py

================================================================================

FILE_START: requests/phoneme_timestamps.py (11/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/phoneme_timestamps.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing


class PhonemeTimestampsParams(typing_extensions.TypedDict):
    phonemes: typing.Sequence[str]
    start: typing.Sequence[float]
    end: typing.Sequence[float]


--------------------------------------------------------------------------------
FILE_END: requests/phoneme_timestamps.py

================================================================================

FILE_START: requests/raw_output_format.py (12/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/raw_output_format.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
from ..types.raw_encoding import RawEncoding
import typing_extensions


class RawOutputFormatParams(typing_extensions.TypedDict):
    encoding: RawEncoding
    sample_rate: int
    bit_rate: typing_extensions.NotRequired[int]


--------------------------------------------------------------------------------
FILE_END: requests/raw_output_format.py

================================================================================

FILE_START: requests/speed.py (13/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/speed.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing
from ..types.numerical_specifier import NumericalSpecifier
from ..types.natural_specifier import NaturalSpecifier

SpeedParams = typing.Union[NumericalSpecifier, NaturalSpecifier]


--------------------------------------------------------------------------------
FILE_END: requests/speed.py

================================================================================

FILE_START: requests/tts_request.py (14/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/tts_request.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
from .tts_request_voice_specifier import TtsRequestVoiceSpecifierParams
import typing_extensions
from ..types.supported_language import SupportedLanguage
from .output_format import OutputFormatParams


class TtsRequestParams(typing_extensions.TypedDict):
    model_id: str
    """
    The ID of the model to use for the generation. See [Models](/build-with-sonic/models) for available models.
    """

    transcript: str
    voice: TtsRequestVoiceSpecifierParams
    language: typing_extensions.NotRequired[SupportedLanguage]
    output_format: OutputFormatParams
    duration: typing_extensions.NotRequired[float]
    """
    The maximum duration of the audio in seconds. You do not usually need to specify this.
    If the duration is not appropriate for the length of the transcript, the output audio may be truncated.
    """


--------------------------------------------------------------------------------
FILE_END: requests/tts_request.py

================================================================================

FILE_START: requests/tts_request_embedding_specifier.py (15/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/tts_request_embedding_specifier.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing
from ...embedding.types.embedding import Embedding
import typing_extensions
from .controls import ControlsParams
from ...core.serialization import FieldMetadata


class TtsRequestEmbeddingSpecifierParams(typing_extensions.TypedDict):
    mode: typing.Literal["embedding"]
    embedding: Embedding
    experimental_controls: typing_extensions.NotRequired[
        typing_extensions.Annotated[ControlsParams, FieldMetadata(alias="__experimental_controls")]
    ]


--------------------------------------------------------------------------------
FILE_END: requests/tts_request_embedding_specifier.py

================================================================================

FILE_START: requests/tts_request_id_specifier.py (16/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/tts_request_id_specifier.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing
from ...voices.types.voice_id import VoiceId
import typing_extensions
from .controls import ControlsParams
from ...core.serialization import FieldMetadata


class TtsRequestIdSpecifierParams(typing_extensions.TypedDict):
    mode: typing.Literal["id"]
    id: VoiceId
    experimental_controls: typing_extensions.NotRequired[
        typing_extensions.Annotated[ControlsParams, FieldMetadata(alias="__experimental_controls")]
    ]


--------------------------------------------------------------------------------
FILE_END: requests/tts_request_id_specifier.py

================================================================================

FILE_START: requests/tts_request_voice_specifier.py (17/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/tts_request_voice_specifier.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing
from .tts_request_id_specifier import TtsRequestIdSpecifierParams
from .tts_request_embedding_specifier import TtsRequestEmbeddingSpecifierParams

TtsRequestVoiceSpecifierParams = typing.Union[TtsRequestIdSpecifierParams, TtsRequestEmbeddingSpecifierParams]


--------------------------------------------------------------------------------
FILE_END: requests/tts_request_voice_specifier.py

================================================================================

FILE_START: requests/wav_output_format.py (18/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/wav_output_format.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .raw_output_format import RawOutputFormatParams


class WavOutputFormatParams(RawOutputFormatParams):
    pass


--------------------------------------------------------------------------------
FILE_END: requests/wav_output_format.py

================================================================================

FILE_START: requests/web_socket_base_response.py (19/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_base_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing_extensions
from ..types.context_id import ContextId


class WebSocketBaseResponseParams(typing_extensions.TypedDict):
    context_id: typing_extensions.NotRequired[ContextId]
    status_code: int
    done: bool


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_base_response.py

================================================================================

FILE_START: requests/web_socket_chunk_response.py (20/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_chunk_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .web_socket_base_response import WebSocketBaseResponseParams


class WebSocketChunkResponseParams(WebSocketBaseResponseParams):
    data: str
    step_time: float


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_chunk_response.py

================================================================================

FILE_START: requests/web_socket_done_response.py (21/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_done_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .web_socket_base_response import WebSocketBaseResponseParams


class WebSocketDoneResponseParams(WebSocketBaseResponseParams):
    pass


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_done_response.py

================================================================================

FILE_START: requests/web_socket_error_response.py (22/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_error_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .web_socket_base_response import WebSocketBaseResponseParams


class WebSocketErrorResponseParams(WebSocketBaseResponseParams):
    error: str


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_error_response.py

================================================================================

FILE_START: requests/web_socket_flush_done_response.py (23/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_flush_done_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .web_socket_base_response import WebSocketBaseResponseParams
from ..types.flush_id import FlushId


class WebSocketFlushDoneResponseParams(WebSocketBaseResponseParams):
    flush_id: FlushId
    flush_done: bool


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_flush_done_response.py

================================================================================

FILE_START: requests/web_socket_phoneme_timestamps_response.py (24/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_phoneme_timestamps_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .web_socket_base_response import WebSocketBaseResponseParams
import typing_extensions
from .phoneme_timestamps import PhonemeTimestampsParams


class WebSocketPhonemeTimestampsResponseParams(WebSocketBaseResponseParams):
    phoneme_timestamps: typing_extensions.NotRequired[PhonemeTimestampsParams]


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_phoneme_timestamps_response.py

================================================================================

FILE_START: requests/web_socket_raw_output_format.py (25/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_raw_output_format.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing
from ..types.raw_encoding import RawEncoding


class WebSocketRawOutputFormatParams(typing_extensions.TypedDict):
    container: typing.Literal["raw"]
    encoding: RawEncoding
    sample_rate: int


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_raw_output_format.py

================================================================================

FILE_START: requests/web_socket_request.py (26/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_request.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing
from .generation_request import GenerationRequestParams
from .cancel_context_request import CancelContextRequestParams

WebSocketRequestParams = typing.Union[GenerationRequestParams, CancelContextRequestParams]


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_request.py

================================================================================

FILE_START: requests/web_socket_response.py (27/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from __future__ import annotations
import typing_extensions
import typing
import typing_extensions
from ..types.context_id import ContextId
from ..types.flush_id import FlushId
from .word_timestamps import WordTimestampsParams
from .phoneme_timestamps import PhonemeTimestampsParams


class WebSocketResponse_ChunkParams(typing_extensions.TypedDict):
    type: typing.Literal["chunk"]
    data: str
    step_time: float
    context_id: typing_extensions.NotRequired[ContextId]
    status_code: int
    done: bool


class WebSocketResponse_FlushDoneParams(typing_extensions.TypedDict):
    type: typing.Literal["flush_done"]
    flush_id: FlushId
    flush_done: bool
    context_id: typing_extensions.NotRequired[ContextId]
    status_code: int
    done: bool


class WebSocketResponse_DoneParams(typing_extensions.TypedDict):
    type: typing.Literal["done"]
    context_id: typing_extensions.NotRequired[ContextId]
    status_code: int
    done: bool


class WebSocketResponse_TimestampsParams(typing_extensions.TypedDict):
    type: typing.Literal["timestamps"]
    word_timestamps: typing_extensions.NotRequired[WordTimestampsParams]
    context_id: typing_extensions.NotRequired[ContextId]
    status_code: int
    done: bool


class WebSocketResponse_ErrorParams(typing_extensions.TypedDict):
    type: typing.Literal["error"]
    error: str
    context_id: typing_extensions.NotRequired[ContextId]
    status_code: int
    done: bool


class WebSocketResponse_PhonemeTimestampsParams(typing_extensions.TypedDict):
    type: typing.Literal["phoneme_timestamps"]
    phoneme_timestamps: typing_extensions.NotRequired[PhonemeTimestampsParams]
    context_id: typing_extensions.NotRequired[ContextId]
    status_code: int
    done: bool


WebSocketResponseParams = typing.Union[
    WebSocketResponse_ChunkParams,
    WebSocketResponse_FlushDoneParams,
    WebSocketResponse_DoneParams,
    WebSocketResponse_TimestampsParams,
    WebSocketResponse_ErrorParams,
    WebSocketResponse_PhonemeTimestampsParams,
]


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_response.py

================================================================================

FILE_START: requests/web_socket_stream_options.py (28/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_stream_options.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing_extensions


class WebSocketStreamOptionsParams(typing_extensions.TypedDict):
    timeout: typing_extensions.NotRequired[float]


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_stream_options.py

================================================================================

FILE_START: requests/web_socket_timestamps_response.py (29/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_timestamps_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .web_socket_base_response import WebSocketBaseResponseParams
import typing_extensions
from .word_timestamps import WordTimestampsParams


class WebSocketTimestampsResponseParams(WebSocketBaseResponseParams):
    word_timestamps: typing_extensions.NotRequired[WordTimestampsParams]


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_timestamps_response.py

================================================================================

FILE_START: requests/web_socket_tts_output.py (30/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_tts_output.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing_extensions
from .word_timestamps import WordTimestampsParams
from .phoneme_timestamps import PhonemeTimestampsParams
import typing
from ..types.context_id import ContextId
from ..types.flush_id import FlushId


class WebSocketTtsOutputParams(typing_extensions.TypedDict):
    word_timestamps: typing_extensions.NotRequired[WordTimestampsParams]
    phoneme_timestamps: typing_extensions.NotRequired[PhonemeTimestampsParams]
    audio: typing_extensions.NotRequired[typing.Optional[typing.Any]]
    context_id: typing_extensions.NotRequired[ContextId]
    flush_id: typing_extensions.NotRequired[FlushId]
    flush_done: typing_extensions.NotRequired[bool]


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_tts_output.py

================================================================================

FILE_START: requests/web_socket_tts_request.py (31/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/web_socket_tts_request.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing_extensions
from .output_format import OutputFormatParams
from .tts_request_voice_specifier import TtsRequestVoiceSpecifierParams
from ...core.serialization import FieldMetadata


class WebSocketTtsRequestParams(typing_extensions.TypedDict):
    model_id: str
    """
    The ID of the model to use for the generation. See [Models](/build-with-sonic/models) for available models.
    """

    output_format: typing_extensions.NotRequired[OutputFormatParams]
    transcript: typing_extensions.NotRequired[str]
    voice: TtsRequestVoiceSpecifierParams
    duration: typing_extensions.NotRequired[int]
    language: typing_extensions.NotRequired[str]
    add_timestamps: typing_extensions.NotRequired[bool]
    add_phoneme_timestamps: typing_extensions.NotRequired[bool]
    continue_: typing_extensions.NotRequired[typing_extensions.Annotated[bool, FieldMetadata(alias="continue")]]
    context_id: typing_extensions.NotRequired[str]


--------------------------------------------------------------------------------
FILE_END: requests/web_socket_tts_request.py

================================================================================

FILE_START: requests/word_timestamps.py (32/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/requests/word_timestamps.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing


class WordTimestampsParams(typing_extensions.TypedDict):
    words: typing.Sequence[str]
    start: typing.Sequence[float]
    end: typing.Sequence[float]


--------------------------------------------------------------------------------
FILE_END: requests/word_timestamps.py

================================================================================

FILE_START: socket_client.py (33/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/socket_client.py
--------------------------------------------------------------------------------

import io
import typing
from json.decoder import JSONDecodeError

from pydub import AudioSegment  # type: ignore

from ..core.api_error import ApiError
from ._async_websocket import AsyncTtsWebsocket
from ._websocket import TtsWebsocket
from .client import AsyncTtsClient, TtsClient
from .requests import TtsRequestVoiceSpecifierParams
from .requests.output_format import OutputFormatParams
from .utils.tts import concat_audio_segments, get_output_format


class TtsClientWithWebsocket(TtsClient):
    """
    Extension of TtsClient that supports a synchronous WebSocket TTS connection.
    """

    def __init__(self, *, client_wrapper):
        super().__init__(client_wrapper=client_wrapper)

    def get_output_format(self, output_format_name: str) -> OutputFormatParams:
        return get_output_format(output_format_name)

    def _ws_url(self):
        base_url = self._client_wrapper.get_base_url()
        if base_url.startswith("ws://") or base_url.startswith("wss://"):
            return base_url
        else:
            prefix = "ws" if "localhost" in base_url else "wss"
            base_url_without_protocol = base_url.split("://")[-1]
            return f"{prefix}://{base_url_without_protocol}"

    def infill(
        self,
        *,
        model_id: str,
        language: str,
        transcript: str,
        voice: TtsRequestVoiceSpecifierParams,
        output_format: OutputFormatParams,
        left_audio_path: typing.Optional[str] = None,
        right_audio_path: typing.Optional[str] = None,
    ) -> typing.Tuple[bytes, bytes]:
        """Generate infill audio between two existing audio segments.

        Args:
            model_id: The ID of the model to use for generating audio
            language: The language of the transcript
            transcript: The text to synthesize
            voice: The voice to use for generating audio
            output_format: The desired audio output format
            left_audio_path: Path to the audio file that comes before the infill
            right_audio_path: Path to the audio file that comes after the infill

        Returns:
            A tuple containing:
            - The generated infill audio (bytes)
            - The complete concatenated audio (bytes)
        """
        if not left_audio_path and not right_audio_path:
            raise ValueError(
                "Must specify at least one of left_audio_path or right_audio_path"
            )

        if voice["mode"] != "id":
            raise ValueError("Infill is only supported for id-based voice specifiers")

        if output_format["container"] == "raw":
            raise ValueError(
                "Raw format is not supported for infill. Use wav or mp3 format instead."
            )

        headers = self._client_wrapper.get_headers()
        headers.pop("Content-Type", None)

        left_audio_file = None
        right_audio_file = None
        try:
            files = {}
            if left_audio_path:
                left_audio_file = open(left_audio_path, "rb")
                files["left_audio"] = left_audio_file
            if right_audio_path:
                right_audio_file = open(right_audio_path, "rb")
                files["right_audio"] = right_audio_file

            # Construct form data with output_format fields directly
            data = {
                "model_id": model_id,
                "language": language,
                "transcript": transcript,
                "voice_id": voice["id"],
                "output_format[container]": output_format["container"],
                "output_format[sample_rate]": output_format["sample_rate"],
            }

            # Add bit_rate for mp3 container
            if "bit_rate" in output_format and output_format["bit_rate"] is not None:
                data["output_format[bit_rate]"] = output_format["bit_rate"]
            if (
                output_format["container"] != "mp3"
                and "encoding" in output_format
                and output_format["encoding"] is not None
            ):
                data["output_format[encoding]"] = output_format["encoding"]

            _response = self._client_wrapper.httpx_client.request(
                "infill/bytes",
                method="POST",
                files=files,  # type: ignore
                data=data,
                headers=headers,
            )
            try:
                if 200 <= _response.status_code < 300:
                    if left_audio_file:
                        left_audio_file.seek(0)
                        left_audio = left_audio_file.read()
                    else:
                        left_audio = None

                    if right_audio_file:
                        right_audio_file.seek(0)
                        right_audio = right_audio_file.read()
                    else:
                        right_audio = None

                    infill_audio = _response.content
                    format = output_format["container"].lower()
                    total_audio = concat_audio_segments(
                        left_audio, infill_audio, right_audio, format=format
                    )
                    return infill_audio, total_audio

                _response_json = _response.json()
            except JSONDecodeError:
                raise ApiError(status_code=_response.status_code, body=_response.text)
            raise ApiError(status_code=_response.status_code, body=_response_json)

        finally:
            if left_audio_file:
                left_audio_file.close()
            if right_audio_file:
                right_audio_file.close()

    def websocket(self):
        client_headers = self._client_wrapper.get_headers()
        ws = TtsWebsocket(
            ws_url=self._ws_url(),
            cartesia_version=client_headers["Cartesia-Version"],
            api_key=client_headers["X-API-Key"],
        )
        ws.connect()
        return ws


class AsyncTtsClientWithWebsocket(AsyncTtsClient):
    """
    Extension of AsyncTtsClient that supports an asynchronous WebSocket TTS connection.
    """

    def __init__(self, *, client_wrapper, get_session):
        super().__init__(client_wrapper=client_wrapper)
        self._get_session = get_session

    def get_output_format(self, output_format_name: str) -> OutputFormatParams:
        return get_output_format(output_format_name)

    def _ws_url(self) -> str:
        base_url = self._client_wrapper.get_base_url()
        if base_url.startswith("ws://") or base_url.startswith("wss://"):
            return base_url
        else:
            prefix = "ws" if "localhost" in base_url else "wss"
            base_url_without_protocol = base_url.split("://")[-1]
            return f"{prefix}://{base_url_without_protocol}"

    async def infill(
        self,
        *,
        model_id: str,
        language: str,
        transcript: str,
        voice: TtsRequestVoiceSpecifierParams,
        output_format: OutputFormatParams,
        left_audio_path: typing.Optional[str] = None,
        right_audio_path: typing.Optional[str] = None,
    ) -> typing.Tuple[bytes, bytes]:
        """Generate infill audio between two existing audio segments.
        Args:
            model_id: The ID of the model to use for generating audio
            language: The language of the transcript
            transcript: The text to synthesize
            voice_id: The ID of the voice to use for generating audio
            output_format: The desired audio output format
            left_audio_path: Path to the audio file that comes before the infill
            right_audio_path: Path to the audio file that comes after the infill
            experimental_voice_controls: Optional voice control parameters
        Returns:
            A tuple containing:
            - The generated infill audio (bytes)
            - The complete concatenated audio (bytes)
        """
        if not left_audio_path and not right_audio_path:
            raise ValueError(
                "Must specify at least one of left_audio_path or right_audio_path"
            )

        if voice["mode"] != "id":
            raise ValueError("Infill is only supported for id-based voice specifiers")

        if output_format["container"] == "raw":
            raise ValueError(
                "Raw format is not supported for infill. Use wav or mp3 format instead."
            )

        headers = self._client_wrapper.get_headers()
        headers.pop("Content-Type", None)

        left_audio_file = None
        right_audio_file = None
        try:
            files = {}
            if left_audio_path:
                left_audio_file = open(left_audio_path, "rb")
                files["left_audio"] = left_audio_file
            if right_audio_path:
                right_audio_file = open(right_audio_path, "rb")
                files["right_audio"] = right_audio_file

            data = {
                "model_id": model_id,
                "language": language,
                "transcript": transcript,
                "voice_id": voice["id"],
                "output_format[container]": output_format["container"],
                "output_format[sample_rate]": output_format["sample_rate"],
            }

            if "bit_rate" in output_format and output_format["bit_rate"] is not None:
                data["output_format[bit_rate]"] = output_format["bit_rate"]
            if (
                output_format["container"] != "mp3"
                and "encoding" in output_format
                and output_format["encoding"] is not None
            ):
                data["output_format[encoding]"] = output_format["encoding"]

            _response = await self._client_wrapper.httpx_client.request(
                "infill/bytes",
                method="POST",
                files=files,  # type: ignore
                headers=headers,
                data=data,
                request_options=None,
            )

            try:
                if 200 <= _response.status_code < 300:
                    if left_audio_file:
                        left_audio_file.seek(0)
                        left_audio = left_audio_file.read()
                    else:
                        left_audio = None

                    if right_audio_file:
                        right_audio_file.seek(0)
                        right_audio = right_audio_file.read()
                    else:
                        right_audio = None

                    infill_audio = _response.content
                    audio_format = output_format["container"].lower()
                    total_audio = concat_audio_segments(
                        left_audio, infill_audio, right_audio, format=audio_format
                    )
                    return infill_audio, total_audio

                _response_json = _response.json()
            except JSONDecodeError:
                raise ApiError(status_code=_response.status_code, body=_response.text)
            raise ApiError(status_code=_response.status_code, body=_response_json)

        finally:
            if left_audio_file:
                left_audio_file.close()
            if right_audio_file:
                right_audio_file.close()

    async def websocket(self):
        client_headers = self._client_wrapper.get_headers()
        ws = AsyncTtsWebsocket(
            ws_url=self._ws_url(),
            cartesia_version=client_headers["Cartesia-Version"],
            api_key=client_headers["X-API-Key"],
            get_session=self._get_session,
        )
        await ws.connect()
        return ws


--------------------------------------------------------------------------------
FILE_END: socket_client.py

================================================================================

FILE_START: types/__init__.py (34/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/__init__.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .cancel_context_request import CancelContextRequest
from .context_id import ContextId
from .controls import Controls
from .emotion import Emotion
from .flush_id import FlushId
from .generation_request import GenerationRequest
from .mp_3_output_format import Mp3OutputFormat
from .natural_specifier import NaturalSpecifier
from .numerical_specifier import NumericalSpecifier
from .output_format import OutputFormat, OutputFormat_Mp3, OutputFormat_Raw, OutputFormat_Wav
from .phoneme_timestamps import PhonemeTimestamps
from .raw_encoding import RawEncoding
from .raw_output_format import RawOutputFormat
from .speed import Speed
from .supported_language import SupportedLanguage
from .tts_request import TtsRequest
from .tts_request_embedding_specifier import TtsRequestEmbeddingSpecifier
from .tts_request_id_specifier import TtsRequestIdSpecifier
from .tts_request_voice_specifier import TtsRequestVoiceSpecifier
from .wav_output_format import WavOutputFormat
from .web_socket_base_response import WebSocketBaseResponse
from .web_socket_chunk_response import WebSocketChunkResponse
from .web_socket_done_response import WebSocketDoneResponse
from .web_socket_error_response import WebSocketErrorResponse
from .web_socket_flush_done_response import WebSocketFlushDoneResponse
from .web_socket_phoneme_timestamps_response import WebSocketPhonemeTimestampsResponse
from .web_socket_raw_output_format import WebSocketRawOutputFormat
from .web_socket_request import WebSocketRequest
from .web_socket_response import (
    WebSocketResponse,
    WebSocketResponse_Chunk,
    WebSocketResponse_Done,
    WebSocketResponse_Error,
    WebSocketResponse_FlushDone,
    WebSocketResponse_PhonemeTimestamps,
    WebSocketResponse_Timestamps,
)
from .web_socket_stream_options import WebSocketStreamOptions
from .web_socket_timestamps_response import WebSocketTimestampsResponse
from .web_socket_tts_output import WebSocketTtsOutput
from .web_socket_tts_request import WebSocketTtsRequest
from .word_timestamps import WordTimestamps

__all__ = [
    "CancelContextRequest",
    "ContextId",
    "Controls",
    "Emotion",
    "FlushId",
    "GenerationRequest",
    "Mp3OutputFormat",
    "NaturalSpecifier",
    "NumericalSpecifier",
    "OutputFormat",
    "OutputFormat_Mp3",
    "OutputFormat_Raw",
    "OutputFormat_Wav",
    "PhonemeTimestamps",
    "RawEncoding",
    "RawOutputFormat",
    "Speed",
    "SupportedLanguage",
    "TtsRequest",
    "TtsRequestEmbeddingSpecifier",
    "TtsRequestIdSpecifier",
    "TtsRequestVoiceSpecifier",
    "WavOutputFormat",
    "WebSocketBaseResponse",
    "WebSocketChunkResponse",
    "WebSocketDoneResponse",
    "WebSocketErrorResponse",
    "WebSocketFlushDoneResponse",
    "WebSocketPhonemeTimestampsResponse",
    "WebSocketRawOutputFormat",
    "WebSocketRequest",
    "WebSocketResponse",
    "WebSocketResponse_Chunk",
    "WebSocketResponse_Done",
    "WebSocketResponse_Error",
    "WebSocketResponse_FlushDone",
    "WebSocketResponse_PhonemeTimestamps",
    "WebSocketResponse_Timestamps",
    "WebSocketStreamOptions",
    "WebSocketTimestampsResponse",
    "WebSocketTtsOutput",
    "WebSocketTtsRequest",
    "WordTimestamps",
]


--------------------------------------------------------------------------------
FILE_END: types/__init__.py

================================================================================

FILE_START: types/cancel_context_request.py (35/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/cancel_context_request.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
from .context_id import ContextId
import pydantic
import typing
from ...core.pydantic_utilities import IS_PYDANTIC_V2


class CancelContextRequest(UniversalBaseModel):
    context_id: ContextId = pydantic.Field()
    """
    The ID of the context to cancel.
    """

    cancel: typing.Literal[True] = pydantic.Field(default=True)
    """
    Whether to cancel the context, so that no more messages are generated for that context.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/cancel_context_request.py

================================================================================

FILE_START: types/context_id.py (36/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/context_id.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

ContextId = str


--------------------------------------------------------------------------------
FILE_END: types/context_id.py

================================================================================

FILE_START: types/controls.py (37/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/controls.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
from .speed import Speed
import typing
from .emotion import Emotion
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic


class Controls(UniversalBaseModel):
    speed: Speed
    emotion: typing.List[Emotion]

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/controls.py

================================================================================

FILE_START: types/emotion.py (38/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/emotion.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing

Emotion = typing.Union[
    typing.Literal[
        "anger:lowest",
        "anger:low",
        "anger:high",
        "anger:highest",
        "positivity:lowest",
        "positivity:low",
        "positivity:high",
        "positivity:highest",
        "surprise:lowest",
        "surprise:low",
        "surprise:high",
        "surprise:highest",
        "sadness:lowest",
        "sadness:low",
        "sadness:high",
        "sadness:highest",
        "curiosity:lowest",
        "curiosity:low",
        "curiosity:high",
        "curiosity:highest",
    ],
    typing.Any,
]


--------------------------------------------------------------------------------
FILE_END: types/emotion.py

================================================================================

FILE_START: types/flush_id.py (39/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/flush_id.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

FlushId = int


--------------------------------------------------------------------------------
FILE_END: types/flush_id.py

================================================================================

FILE_START: types/generation_request.py (40/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/generation_request.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
import pydantic
import typing
from .tts_request_voice_specifier import TtsRequestVoiceSpecifier
from .supported_language import SupportedLanguage
from .web_socket_raw_output_format import WebSocketRawOutputFormat
from .context_id import ContextId
import typing_extensions
from ...core.serialization import FieldMetadata
from ...core.pydantic_utilities import IS_PYDANTIC_V2


class GenerationRequest(UniversalBaseModel):
    model_id: str = pydantic.Field()
    """
    The ID of the model to use for the generation. See [Models](/build-with-sonic/models) for available models.
    """

    transcript: typing.Optional[typing.Any] = pydantic.Field(default=None)
    """
    The transcript to generate speech for. This can be a string or an iterator over strings.
    """

    voice: TtsRequestVoiceSpecifier
    language: typing.Optional[SupportedLanguage] = None
    output_format: WebSocketRawOutputFormat
    duration: typing.Optional[float] = pydantic.Field(default=None)
    """
    The maximum duration of the audio in seconds. You do not usually need to specify this.
    If the duration is not appropriate for the length of the transcript, the output audio may be truncated.
    """

    context_id: typing.Optional[ContextId] = None
    continue_: typing_extensions.Annotated[typing.Optional[bool], FieldMetadata(alias="continue")] = pydantic.Field(
        default=None
    )
    """
    Whether this input may be followed by more inputs.
    If not specified, this defaults to `false`.
    """

    flush: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Whether to flush the context.
    """

    add_timestamps: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Whether to return word-level timestamps.
    """

    add_phoneme_timestamps: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Whether to return phoneme-level timestamps.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/generation_request.py

================================================================================

FILE_START: types/mp_3_output_format.py (41/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/mp_3_output_format.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
import pydantic
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import typing


class Mp3OutputFormat(UniversalBaseModel):
    sample_rate: int
    bit_rate: int = pydantic.Field()
    """
    The bit rate of the audio in bits per second. Supported bit rates are 32000, 64000, 96000, 128000, 192000.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/mp_3_output_format.py

================================================================================

FILE_START: types/natural_specifier.py (42/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/natural_specifier.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing

NaturalSpecifier = typing.Union[typing.Literal["slowest", "slow", "normal", "fast", "fastest"], typing.Any]


--------------------------------------------------------------------------------
FILE_END: types/natural_specifier.py

================================================================================

FILE_START: types/numerical_specifier.py (43/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/numerical_specifier.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

NumericalSpecifier = float


--------------------------------------------------------------------------------
FILE_END: types/numerical_specifier.py

================================================================================

FILE_START: types/output_format.py (44/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/output_format.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from __future__ import annotations
from ...core.pydantic_utilities import UniversalBaseModel
import typing
from .raw_encoding import RawEncoding
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic


class OutputFormat_Raw(UniversalBaseModel):
    container: typing.Literal["raw"] = "raw"
    encoding: RawEncoding
    sample_rate: int
    bit_rate: typing.Optional[int] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class OutputFormat_Wav(UniversalBaseModel):
    container: typing.Literal["wav"] = "wav"
    encoding: RawEncoding
    sample_rate: int
    bit_rate: typing.Optional[int] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class OutputFormat_Mp3(UniversalBaseModel):
    container: typing.Literal["mp3"] = "mp3"
    sample_rate: int
    bit_rate: int

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


OutputFormat = typing.Union[OutputFormat_Raw, OutputFormat_Wav, OutputFormat_Mp3]


--------------------------------------------------------------------------------
FILE_END: types/output_format.py

================================================================================

FILE_START: types/phoneme_timestamps.py (45/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/phoneme_timestamps.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
import typing
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic


class PhonemeTimestamps(UniversalBaseModel):
    phonemes: typing.List[str]
    start: typing.List[float]
    end: typing.List[float]

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/phoneme_timestamps.py

================================================================================

FILE_START: types/raw_encoding.py (46/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/raw_encoding.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing

RawEncoding = typing.Union[typing.Literal["pcm_f32le", "pcm_s16le", "pcm_mulaw", "pcm_alaw"], typing.Any]


--------------------------------------------------------------------------------
FILE_END: types/raw_encoding.py

================================================================================

FILE_START: types/raw_output_format.py (47/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/raw_output_format.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
from .raw_encoding import RawEncoding
import typing
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic


class RawOutputFormat(UniversalBaseModel):
    encoding: RawEncoding
    sample_rate: int
    bit_rate: typing.Optional[int] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/raw_output_format.py

================================================================================

FILE_START: types/speed.py (48/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/speed.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing
from .numerical_specifier import NumericalSpecifier
from .natural_specifier import NaturalSpecifier

Speed = typing.Union[NumericalSpecifier, NaturalSpecifier]


--------------------------------------------------------------------------------
FILE_END: types/speed.py

================================================================================

FILE_START: types/supported_language.py (49/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/supported_language.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing

SupportedLanguage = typing.Union[
    typing.Literal["en", "fr", "de", "es", "pt", "zh", "ja", "hi", "it", "ko", "nl", "pl", "ru", "sv", "tr"], typing.Any
]


--------------------------------------------------------------------------------
FILE_END: types/supported_language.py

================================================================================

FILE_START: types/tts_request.py (50/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/tts_request.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
import pydantic
from .tts_request_voice_specifier import TtsRequestVoiceSpecifier
import typing
from .supported_language import SupportedLanguage
from .output_format import OutputFormat
from ...core.pydantic_utilities import IS_PYDANTIC_V2


class TtsRequest(UniversalBaseModel):
    model_id: str = pydantic.Field()
    """
    The ID of the model to use for the generation. See [Models](/build-with-sonic/models) for available models.
    """

    transcript: str
    voice: TtsRequestVoiceSpecifier
    language: typing.Optional[SupportedLanguage] = None
    output_format: OutputFormat
    duration: typing.Optional[float] = pydantic.Field(default=None)
    """
    The maximum duration of the audio in seconds. You do not usually need to specify this.
    If the duration is not appropriate for the length of the transcript, the output audio may be truncated.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/tts_request.py

================================================================================

FILE_START: types/tts_request_embedding_specifier.py (51/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/tts_request_embedding_specifier.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
import typing
from ...embedding.types.embedding import Embedding
import typing_extensions
from .controls import Controls
from ...core.serialization import FieldMetadata
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic


class TtsRequestEmbeddingSpecifier(UniversalBaseModel):
    mode: typing.Literal["embedding"] = "embedding"
    embedding: Embedding
    experimental_controls: typing_extensions.Annotated[
        typing.Optional[Controls], FieldMetadata(alias="__experimental_controls")
    ] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/tts_request_embedding_specifier.py

================================================================================

FILE_START: types/tts_request_id_specifier.py (52/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/tts_request_id_specifier.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
import typing
from ...voices.types.voice_id import VoiceId
import typing_extensions
from .controls import Controls
from ...core.serialization import FieldMetadata
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic


class TtsRequestIdSpecifier(UniversalBaseModel):
    mode: typing.Literal["id"] = "id"
    id: VoiceId
    experimental_controls: typing_extensions.Annotated[
        typing.Optional[Controls], FieldMetadata(alias="__experimental_controls")
    ] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/tts_request_id_specifier.py

================================================================================

FILE_START: types/tts_request_voice_specifier.py (53/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/tts_request_voice_specifier.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing
from .tts_request_id_specifier import TtsRequestIdSpecifier
from .tts_request_embedding_specifier import TtsRequestEmbeddingSpecifier

TtsRequestVoiceSpecifier = typing.Union[TtsRequestIdSpecifier, TtsRequestEmbeddingSpecifier]


--------------------------------------------------------------------------------
FILE_END: types/tts_request_voice_specifier.py

================================================================================

FILE_START: types/wav_output_format.py (54/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/wav_output_format.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .raw_output_format import RawOutputFormat
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import typing
import pydantic


class WavOutputFormat(RawOutputFormat):
    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/wav_output_format.py

================================================================================

FILE_START: types/web_socket_base_response.py (55/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_base_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
import typing
from .context_id import ContextId
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic


class WebSocketBaseResponse(UniversalBaseModel):
    context_id: typing.Optional[ContextId] = None
    status_code: int
    done: bool

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/web_socket_base_response.py

================================================================================

FILE_START: types/web_socket_chunk_response.py (56/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_chunk_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .web_socket_base_response import WebSocketBaseResponse
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import typing
import pydantic


class WebSocketChunkResponse(WebSocketBaseResponse):
    data: str
    step_time: float

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/web_socket_chunk_response.py

================================================================================

FILE_START: types/web_socket_done_response.py (57/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_done_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .web_socket_base_response import WebSocketBaseResponse
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import typing
import pydantic


class WebSocketDoneResponse(WebSocketBaseResponse):
    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/web_socket_done_response.py

================================================================================

FILE_START: types/web_socket_error_response.py (58/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_error_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .web_socket_base_response import WebSocketBaseResponse
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import typing
import pydantic


class WebSocketErrorResponse(WebSocketBaseResponse):
    error: str

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/web_socket_error_response.py

================================================================================

FILE_START: types/web_socket_flush_done_response.py (59/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_flush_done_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .web_socket_base_response import WebSocketBaseResponse
from .flush_id import FlushId
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import typing
import pydantic


class WebSocketFlushDoneResponse(WebSocketBaseResponse):
    flush_id: FlushId
    flush_done: bool

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/web_socket_flush_done_response.py

================================================================================

FILE_START: types/web_socket_phoneme_timestamps_response.py (60/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_phoneme_timestamps_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .web_socket_base_response import WebSocketBaseResponse
import typing
from .phoneme_timestamps import PhonemeTimestamps
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic


class WebSocketPhonemeTimestampsResponse(WebSocketBaseResponse):
    phoneme_timestamps: typing.Optional[PhonemeTimestamps] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/web_socket_phoneme_timestamps_response.py

================================================================================

FILE_START: types/web_socket_raw_output_format.py (61/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_raw_output_format.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
import typing
from .raw_encoding import RawEncoding
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic


class WebSocketRawOutputFormat(UniversalBaseModel):
    container: typing.Literal["raw"] = "raw"
    encoding: RawEncoding
    sample_rate: int

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/web_socket_raw_output_format.py

================================================================================

FILE_START: types/web_socket_request.py (62/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_request.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing
from .generation_request import GenerationRequest
from .cancel_context_request import CancelContextRequest

WebSocketRequest = typing.Union[GenerationRequest, CancelContextRequest]


--------------------------------------------------------------------------------
FILE_END: types/web_socket_request.py

================================================================================

FILE_START: types/web_socket_response.py (63/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from __future__ import annotations
from ...core.pydantic_utilities import UniversalBaseModel
import typing
from .context_id import ContextId
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic
from .flush_id import FlushId
from .word_timestamps import WordTimestamps
from .phoneme_timestamps import PhonemeTimestamps


class WebSocketResponse_Chunk(UniversalBaseModel):
    type: typing.Literal["chunk"] = "chunk"
    data: str
    step_time: float
    context_id: typing.Optional[ContextId] = None
    status_code: int
    done: bool

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class WebSocketResponse_FlushDone(UniversalBaseModel):
    type: typing.Literal["flush_done"] = "flush_done"
    flush_id: FlushId
    flush_done: bool
    context_id: typing.Optional[ContextId] = None
    status_code: int
    done: bool

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class WebSocketResponse_Done(UniversalBaseModel):
    type: typing.Literal["done"] = "done"
    context_id: typing.Optional[ContextId] = None
    status_code: int
    done: bool

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class WebSocketResponse_Timestamps(UniversalBaseModel):
    type: typing.Literal["timestamps"] = "timestamps"
    word_timestamps: typing.Optional[WordTimestamps] = None
    context_id: typing.Optional[ContextId] = None
    status_code: int
    done: bool

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class WebSocketResponse_Error(UniversalBaseModel):
    type: typing.Literal["error"] = "error"
    error: str
    context_id: typing.Optional[ContextId] = None
    status_code: int
    done: bool

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


class WebSocketResponse_PhonemeTimestamps(UniversalBaseModel):
    type: typing.Literal["phoneme_timestamps"] = "phoneme_timestamps"
    phoneme_timestamps: typing.Optional[PhonemeTimestamps] = None
    context_id: typing.Optional[ContextId] = None
    status_code: int
    done: bool

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


WebSocketResponse = typing.Union[
    WebSocketResponse_Chunk,
    WebSocketResponse_FlushDone,
    WebSocketResponse_Done,
    WebSocketResponse_Timestamps,
    WebSocketResponse_Error,
    WebSocketResponse_PhonemeTimestamps,
]


--------------------------------------------------------------------------------
FILE_END: types/web_socket_response.py

================================================================================

FILE_START: types/web_socket_stream_options.py (64/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_stream_options.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
import typing
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic


class WebSocketStreamOptions(UniversalBaseModel):
    timeout: typing.Optional[float] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/web_socket_stream_options.py

================================================================================

FILE_START: types/web_socket_timestamps_response.py (65/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_timestamps_response.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from .web_socket_base_response import WebSocketBaseResponse
import typing
from .word_timestamps import WordTimestamps
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic


class WebSocketTimestampsResponse(WebSocketBaseResponse):
    word_timestamps: typing.Optional[WordTimestamps] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/web_socket_timestamps_response.py

================================================================================

FILE_START: types/web_socket_tts_output.py (66/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_tts_output.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

import typing

import pydantic

from ...core.pydantic_utilities import IS_PYDANTIC_V2, UniversalBaseModel
from .context_id import ContextId
from .flush_id import FlushId
from .word_timestamps import WordTimestamps


class WebSocketTtsOutput(UniversalBaseModel):
    word_timestamps: typing.Optional[WordTimestamps] = None
    audio: typing.Optional[bytes] = None
    context_id: typing.Optional[ContextId] = None
    flush_id: typing.Optional[FlushId] = None
    flush_done: typing.Optional[bool] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/web_socket_tts_output.py

================================================================================

FILE_START: types/web_socket_tts_request.py (67/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/web_socket_tts_request.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
import pydantic
import typing
from .output_format import OutputFormat
from .tts_request_voice_specifier import TtsRequestVoiceSpecifier
import typing_extensions
from ...core.serialization import FieldMetadata
from ...core.pydantic_utilities import IS_PYDANTIC_V2


class WebSocketTtsRequest(UniversalBaseModel):
    model_id: str = pydantic.Field()
    """
    The ID of the model to use for the generation. See [Models](/build-with-sonic/models) for available models.
    """

    output_format: typing.Optional[OutputFormat] = None
    transcript: typing.Optional[str] = None
    voice: TtsRequestVoiceSpecifier
    duration: typing.Optional[int] = None
    language: typing.Optional[str] = None
    add_timestamps: typing.Optional[bool] = None
    add_phoneme_timestamps: typing.Optional[bool] = None
    continue_: typing_extensions.Annotated[typing.Optional[bool], FieldMetadata(alias="continue")] = None
    context_id: typing.Optional[str] = None

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/web_socket_tts_request.py

================================================================================

FILE_START: types/word_timestamps.py (68/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/types/word_timestamps.py
--------------------------------------------------------------------------------

# This file was auto-generated by Fern from our API Definition.

from ...core.pydantic_utilities import UniversalBaseModel
import typing
from ...core.pydantic_utilities import IS_PYDANTIC_V2
import pydantic


class WordTimestamps(UniversalBaseModel):
    words: typing.List[str]
    start: typing.List[float]
    end: typing.List[float]

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow


--------------------------------------------------------------------------------
FILE_END: types/word_timestamps.py

================================================================================

FILE_START: utils/constants.py (69/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/utils/constants.py
--------------------------------------------------------------------------------

DEFAULT_MODEL_ID = "sonic-english"  # latest default model
MULTILINGUAL_MODEL_ID = "sonic-multilingual"  # latest multilingual model
DEFAULT_BASE_URL = "api.cartesia.ai"
DEFAULT_CARTESIA_VERSION = "2024-06-10"  # latest version
DEFAULT_OUTPUT_FORMAT = "raw_pcm_f32le_44100"
DEFAULT_TIMEOUT = 30  # seconds
DEFAULT_NUM_CONNECTIONS = 10  # connections per client
DEFAULT_VOICE_EMBEDDING = [1.0] * 192

BACKOFF_FACTOR = 1
MAX_RETRIES = 3


--------------------------------------------------------------------------------
FILE_END: utils/constants.py

================================================================================

FILE_START: utils/tts.py (70/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/utils/tts.py
--------------------------------------------------------------------------------

import io
import typing

from pydub import AudioSegment  # type: ignore

from .types import OutputFormatMapping


def get_output_format(output_format_name: str):
    """Convenience method to get the output_format dictionary from a given output format name.

    Args:
        output_format_name (str): The name of the output format.

    Returns:
        OutputFormat: A dictionary containing the details of the output format to be passed into tts.sse() or tts.websocket().send()

    Raises:
        ValueError: If the output_format name is not supported
    """
    if output_format_name in OutputFormatMapping._format_mapping:
        output_format_obj = OutputFormatMapping.get_format(output_format_name)
    else:
        raise ValueError(f"Unsupported format: {output_format_name}")

    return output_format_obj


def concat_audio_segments(
    left_audio: typing.Optional[bytes],
    infill_audio: bytes,
    right_audio: typing.Optional[bytes],
    format: str = "wav",
) -> bytes:
    """Helper method to concatenate three audio segments while preserving audio format and headers.

    Args:
        left_audio: The audio segment that comes before the infill
        infill_audio: The generated infill audio segment
        right_audio: The audio segment that comes after the infill
        format: The audio format (e.g., 'wav', 'mp3'). Defaults to 'wav'

    Returns:
        bytes: The concatenated audio as bytes

    Raises:
        ValueError: If the audio segments cannot be loaded or concatenated
    """
    try:
        combined = AudioSegment.empty()
        if left_audio:
            combined += AudioSegment.from_file(io.BytesIO(left_audio), format=format)

        combined += AudioSegment.from_file(io.BytesIO(infill_audio), format=format)

        if right_audio:
            combined += AudioSegment.from_file(io.BytesIO(right_audio), format=format)

        output = io.BytesIO()
        combined.export(output, format=format)
        return output.getvalue()

    except Exception as e:
        raise ValueError(f"Failed to concatenate audio segments: {str(e)}")


--------------------------------------------------------------------------------
FILE_END: utils/tts.py

================================================================================

FILE_START: utils/types.py (71/71)
FILE_PATH: /Users/offbeat/Documents/GitHub/cartesia-python/src/cartesia/tts/utils/types.py
--------------------------------------------------------------------------------

class OutputFormatMapping:
    _format_mapping = {
        "raw_pcm_f32le_44100": {
            "container": "raw",
            "encoding": "pcm_f32le",
            "sample_rate": 44100,
        },
        "raw_pcm_s16le_44100": {
            "container": "raw",
            "encoding": "pcm_s16le",
            "sample_rate": 44100,
        },
        "raw_pcm_f32le_24000": {
            "container": "raw",
            "encoding": "pcm_f32le",
            "sample_rate": 24000,
        },
        "raw_pcm_s16le_24000": {
            "container": "raw",
            "encoding": "pcm_s16le",
            "sample_rate": 24000,
        },
        "raw_pcm_f32le_22050": {
            "container": "raw",
            "encoding": "pcm_f32le",
            "sample_rate": 22050,
        },
        "raw_pcm_s16le_22050": {
            "container": "raw",
            "encoding": "pcm_s16le",
            "sample_rate": 22050,
        },
        "raw_pcm_f32le_16000": {
            "container": "raw",
            "encoding": "pcm_f32le",
            "sample_rate": 16000,
        },
        "raw_pcm_s16le_16000": {
            "container": "raw",
            "encoding": "pcm_s16le",
            "sample_rate": 16000,
        },
        "raw_pcm_f32le_8000": {
            "container": "raw",
            "encoding": "pcm_f32le",
            "sample_rate": 8000,
        },
        "raw_pcm_s16le_8000": {
            "container": "raw",
            "encoding": "pcm_s16le",
            "sample_rate": 8000,
        },
        "raw_pcm_mulaw_8000": {
            "container": "raw",
            "encoding": "pcm_mulaw",
            "sample_rate": 8000,
        },
        "raw_pcm_alaw_8000": {
            "container": "raw",
            "encoding": "pcm_alaw",
            "sample_rate": 8000,
        },
    }

    @classmethod
    def get_format(cls, format_name):
        if format_name in cls._format_mapping:
            return cls._format_mapping[format_name]
        else:
            raise ValueError(f"Unsupported format: {format_name}")


--------------------------------------------------------------------------------
FILE_END: utils/types.py

================================================================================

